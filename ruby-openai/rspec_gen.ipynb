{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":generate_tests_with_chat"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'openai'\n",
    "require 'dotenv/load'\n",
    "\n",
    "def load_env(env_path)\n",
    "  Dotenv.load(env_path) ? \"Environment variables loaded\" : \"Environment variables not loaded\"\n",
    "end\n",
    "\n",
    "def openai_client\n",
    "  @openai_client ||= OpenAI::Client.new(access_token: ENV[\"OPENAI_API_KEY\"], request_timeout: 100000)\n",
    "end\n",
    "\n",
    "def sample_files_path\n",
    "  @sample_files_path ||= \"ruby-openai/sample_files\"\n",
    "end\n",
    "\n",
    "def files_rb\n",
    "  @files_rb ||= Dir.glob(\"#{sample_files_path}/*\")\n",
    "end\n",
    "\n",
    "def files\n",
    "  @files = files_rb.map { |file| { file: { name: file, content: File.read(file) } } }\n",
    "end\n",
    "\n",
    "def message(code)\n",
    "  {\n",
    "    role: \"user\",\n",
    "    content: \"Generate RSpec tests for the following code:\n",
    "    \\n#{code}\\n\"\n",
    "  }\n",
    "end\n",
    "\n",
    "def chat_paramaters(message, max_tokens)\n",
    "  {\n",
    "    model: \"gpt-3.5-turbo\",\n",
    "    messages: [message],\n",
    "    max_tokens: max_tokens,\n",
    "    temperature: 0.1,\n",
    "    top_p: 1,\n",
    "    frequency_penalty: 0,\n",
    "    presence_penalty: 0\n",
    "  }\n",
    "end\n",
    "\n",
    "def generate_tests_with_chat(files, openai)\n",
    "  Dir.mkdir(\"ruby-openai/rspec\") unless Dir.exist?(\"ruby-openai/rspec\")\n",
    "\n",
    "  files.each do |file|\n",
    "    name = file[:file][:name]\n",
    "    content = file[:file][:content]\n",
    "    puts \"Generating tests for #{name}...\"\n",
    "      \n",
    "    message = message(content)\n",
    "    chat_paramaters = chat_paramaters(message, 1000)\n",
    "    begin\n",
    "      response = openai.chat(parameters: chat_paramaters)\n",
    "      tests = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "      File.open(\"ruby-openai/rspec/#{name.split(\"/\").last.split(\".\").first}_spec.rb\", \"w\") { |f| f.write(tests) }\n",
    "    rescue StandardError => e\n",
    "      puts \"Error: #{e}\"\n",
    "      retry\n",
    "    end\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating tests for ruby-openai/sample_files/subtract.rb...\n",
      "Generating tests for ruby-openai/sample_files/sum.rb...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Done generating tests\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_env(\"ruby-openai/.env\")\n",
    "\"Done generating tests\" if generate_tests_with_chat(files, openai_client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ruby 3.2.1",
   "language": "ruby",
   "name": "ruby"
  },
  "language_info": {
   "file_extension": ".rb",
   "mimetype": "application/x-ruby",
   "name": "ruby",
   "version": "3.2.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
